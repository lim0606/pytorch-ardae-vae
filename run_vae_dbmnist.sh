#!/bin/bash

# baseline models
# resconv
python vae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 32 --optimizer adam --momentum 0.9 --beta1 0.9 --model resconv --model-z-dim 32 --model-h-dim 0 --model-n-layers 0 --model-nonlin elu --model-n-dim 0 --model-clip-logvar none --init-method none --do-m5bias none --exp-num 1 --lr 0.0001 --beta-init 0.0001 --beta-fin 1.0 --beta-annealing 0 --epochs 6400 --eval-iws-interval 5000 --iws-samples 256 --weight-avg none --weight-avg-start -1 --weight-avg-decay 0.998 --log-interval 100 --vis-interval 10000 --ckpt-interval 5000 --train-mode train

# hierarchical resconv
python vae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 32 --optimizer adam --momentum 0.9 --beta1 0.9 --model auxresconv --model-z-dim 32 --model-h-dim 0 --model-n-layers 0 --model-nonlin elu --model-n-dim 100 --model-clip-logvar none --init-method none --do-m5bias none --exp-num 1 --lr 0.0001 --beta-init 0.0001 --beta-fin 1.0 --beta-annealing 0 --epochs 6400 --eval-iws-interval 5000 --iws-samples 256 --weight-avg none --weight-avg-start -1 --weight-avg-decay 0.998 --log-interval 100 --vis-interval 10000 --ckpt-interval 5000 --train-mode train

# conv
python vae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 32 --optimizer adam --momentum 0.5 --beta1 0.5 --model conv --model-z-dim 32 --model-h-dim 0 --model-n-layers 0 --model-nonlin softplus --model-n-dim 0 --model-clip-logvar none --init-method xv --do-m5bias none --exp-num 1 --lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --epochs 4700 --eval-iws-interval 5000 --iws-samples 256 --weight-avg none --weight-avg-start -1 --weight-avg-decay 0.998 --log-interval 100 --vis-interval 10000 --ckpt-interval 5000 --train-mode train

# hierarchical conv
python vae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 32 --optimizer adam --momentum 0.5 --beta1 0.5 --model auxconv --model-z-dim 32 --model-h-dim 0 --model-n-layers 0 --model-nonlin softplus --model-n-dim 100 --model-clip-logvar none --init-method xv --do-m5bias none --exp-num 1 --lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --epochs 4700 --eval-iws-interval 5000 --iws-samples 256 --weight-avg none --weight-avg-start -1 --weight-avg-decay 0.998 --log-interval 100 --vis-interval 10000 --ckpt-interval 5000 --train-mode train

# mlp
python vae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 32 --optimizer adam --momentum 0.5 --beta1 0.5 --model mnist --model-z-dim 32 --model-h-dim 300 --model-n-layers 2 --model-nonlin softplus --model-n-dim 0 --model-clip-logvar none --init-method xv --do-m5bias none --exp-num 1 --lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --epochs 4700 --eval-iws-interval 5000 --iws-samples 256 --weight-avg none --weight-avg-start -1 --weight-avg-decay 0.998 --log-interval 100 --vis-interval 10000 --ckpt-interval 5000 --train-mode train

# hierarchical mlp
python vae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 32 --optimizer adam --momentum 0.5 --beta1 0.5 --model auxmnist --model-z-dim 32 --model-h-dim 300 --model-n-layers 2 --model-nonlin softplus --model-n-dim 100 --model-clip-logvar none --init-method xv --do-m5bias none --exp-num 1 --lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --epochs 4700 --eval-iws-interval 5000 --iws-samples 256 --weight-avg none --weight-avg-start -1 --weight-avg-decay 0.998 --log-interval 100 --vis-interval 10000 --ckpt-interval 5000 --train-mode train


# proposed method
# implicit resconv
python ivae_ardae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 1 --m-optimizer adam --m-momentum 0.9 --m-beta1 0.9 --d-optimizer rmsprop --d-momentum 0.9 --d-beta1 0.9 --train-nstd-cdae 1 --train-nz-cdae 625 --train-nz-model 1 --model resconvct-res --model-z-dim 32 --model-h-dim 512 --model-n-layers 1 --model-nonlin elu --model-n-dim 100 --model-clip-z0-logvar none --model-clip-z-logvar none --cdae mlp-res --cdae-h-dim 512 --cdae-n-layers 5 --cdae-nonlin softplus --cdae-ctx-type lt0 --exp-num 1 --m-lr 0.001 --d-lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --delta 0.1 --std-scale 100 --num-cdae-updates 2 --epochs 6400 --eval-iws-interval 10000 --iws-samples 256 --m-weight-avg none --m-weight-avg-start -1 --m-weight-avg-decay 0.998 --log-interval 100 --vis-interval 50000 --ckpt-interval 10000 --train-mode train

# hierarchical resconv
python ivae_ardae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 1 --m-optimizer adam --m-momentum 0.9 --m-beta1 0.9 --d-optimizer rmsprop --d-momentum 0.9 --d-beta1 0.9 --train-nstd-cdae 1 --train-nz-cdae 625 --train-nz-model 1 --model auxresconvct --model-z-dim 32 --model-h-dim 0 --model-n-layers 0 --model-nonlin elu --model-n-dim 100 --model-clip-z0-logvar none --model-clip-z-logvar none --cdae mlp-res --cdae-h-dim 512 --cdae-n-layers 5 --cdae-nonlin softplus --cdae-ctx-type hidden1a --exp-num 1 --m-lr 0.001 --d-lr 0.0001 --beta-init 0.0001 --beta-fin 1.0 --beta-annealing 50000 --delta 0.1 --std-scale 100 --num-cdae-updates 2 --epochs 6400 --eval-iws-interval 10000 --iws-samples 256 --m-weight-avg none --m-weight-avg-start -1 --m-weight-avg-decay 0.998 --log-interval 100 --vis-interval 50000 --ckpt-interval 5000 --train-mode train

# implicit conv
python ivae_ardae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 1 --m-optimizer adam --m-momentum 0.5 --m-beta1 0.5 --d-optimizer rmsprop --d-momentum 0.5 --d-beta1 0.5 --train-nstd-cdae 1 --train-nz-cdae 625 --train-nz-model 1 --model mnist-conv --model-z-dim 32 --model-h-dim 0 --model-n-layers 0 --model-nonlin softplus --model-n-dim 100 --model-clip-z0-logvar none --model-clip-z-logvar none --cdae mlp-grad --cdae-h-dim 256 --cdae-n-layers 5 --cdae-nonlin softplus --cdae-ctx-type lt0 --exp-num 1 --m-lr 0.0001 --d-lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --delta 0.1 --std-scale 10000 --num-cdae-updates 1 --epochs 6400 --eval-iws-interval 10000 --iws-samples 1024 --m-weight-avg none --m-weight-avg-start -1 --m-weight-avg-decay 0.998 --log-interval 100 --vis-interval 50000 --ckpt-interval 10000 --train-mode train

# hierarchical conv
python ivae_ardae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 1 --m-optimizer adam --m-momentum 0.5 --m-beta1 0.5 --d-optimizer rmsprop --d-momentum 0.5 --d-beta1 0.5 --train-nstd-cdae 1 --train-nz-cdae 625 --train-nz-model 1 --model auxconv --model-z-dim 32 --model-h-dim 0 --model-n-layers 0 --model-nonlin softplus --model-n-dim 100 --model-clip-z0-logvar none --model-clip-z-logvar none --cdae mlp-grad --cdae-h-dim 256 --cdae-n-layers 5 --cdae-nonlin softplus --cdae-ctx-type hidden1a --exp-num 1 --m-lr 0.0001 --d-lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --delta 0.1 --std-scale 10000 --num-cdae-updates 1 --epochs 6400 --eval-iws-interval 10000 --iws-samples 1024 --m-weight-avg none --m-weight-avg-start -1 --m-weight-avg-decay 0.998 --log-interval 100 --vis-interval 50000 --ckpt-interval 10000 --train-mode train

# implicit mlp
python ivae_ardae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 1 --m-optimizer adam --m-momentum 0.5 --m-beta1 0.5 --d-optimizer rmsprop --d-momentum 0.5 --d-beta1 0.5 --train-nstd-cdae 1 --train-nz-cdae 625 --train-nz-model 1 --model mnist-concat --model-z-dim 32 --model-h-dim 300 --model-n-layers 2 --model-nonlin softplus --model-n-dim 100 --model-clip-z0-logvar none --model-clip-z-logvar none --cdae mlp-grad --cdae-h-dim 256 --cdae-n-layers 5 --cdae-nonlin softplus --cdae-ctx-type lt0 --exp-num 1 --m-lr 0.0001 --d-lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --delta 0.1 --std-scale 10000 --num-cdae-updates 1 --epochs 6400 --eval-iws-interval 10000 --iws-samples 1024 --m-weight-avg none --m-weight-avg-start -1 --m-weight-avg-decay 0.998 --log-interval 100 --vis-interval 50000 --ckpt-interval 10000 --train-mode train

# hierarchical mlp
python ivae_ardae.py --cache experiments/dbmnist-val5k --dataset dbmnist-val5k --nheight 28 --nchannels 1 --train-batch-size 128 --eval-batch-size 1 --m-optimizer adam --m-momentum 0.5 --m-beta1 0.5 --d-optimizer rmsprop --d-momentum 0.5 --d-beta1 0.5 --train-nstd-cdae 1 --train-nz-cdae 625 --train-nz-model 1 --model auxmnist --model-z-dim 32 --model-h-dim 300 --model-n-layers 2 --model-nonlin softplus --model-n-dim 100 --model-clip-z0-logvar none --model-clip-z-logvar none --cdae mlp-grad --cdae-h-dim 256 --cdae-n-layers 5 --cdae-nonlin softplus --cdae-ctx-type hidden1a --exp-num 1 --m-lr 0.0001 --d-lr 0.0001 --beta-init 1.0 --beta-fin 1.0 --beta-annealing 0 --delta 0.1 --std-scale 10000 --num-cdae-updates 1 --epochs 6400 --eval-iws-interval 10000 --iws-samples 1024 --m-weight-avg none --m-weight-avg-start -1 --m-weight-avg-decay 0.998 --log-interval 100 --vis-interval 50000 --ckpt-interval 10000 --train-mode train
